{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_tf_intro_nlp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2lmtHF8zcpwMhEY12QQfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/GAIP_12_08_21/blob/main/01_tf_intro_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTmnXtI1Hsc2"
      },
      "source": [
        "# classification-> \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mhYNsGs2PfYF",
        "outputId": "e64895c4-fbc2-44c6-df7f-b6f25a20c18d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn0xpFUnPssK"
      },
      "source": [
        "nlpdata = keras.datasets.imdb\n",
        "imgdata = keras.datasets.fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvKwwvzZQV0M",
        "outputId": "8947f2bc-362f-4921-b3e7-148cb54ee6b7"
      },
      "source": [
        "dir(nlpdata)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_sys',\n",
              " 'get_word_index',\n",
              " 'load_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRW7-d0QZJL",
        "outputId": "538b7e64-ac2a-4783-f54a-81aae0771ca0"
      },
      "source": [
        "dir(imgdata)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_sys',\n",
              " 'load_data']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_Le6h0QdsZ"
      },
      "source": [
        "data = nlpdata.load_data(num_words=10000)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiKKA4aBQv_n",
        "outputId": "5c4f2544-cddf-4fcf-c37b-8e0bcb512c72"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1dAHg8QQ0pm",
        "outputId": "cb7ca074-f001-4d82-c10a-046e407fb5c2"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "        list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "        list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "        ...,\n",
              "        list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "        list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "        list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "       dtype=object), array([1, 0, 0, ..., 0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRf7dwi4Q7w1"
      },
      "source": [
        "xtrain,ytrain = data[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28LayBWJRDYo",
        "outputId": "d9fe785c-8433-4b3e-f217-14bf806c2e74"
      },
      "source": [
        "data[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "        list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 2, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "        list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 8738, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 5421, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 2, 2, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 9909, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 2, 3292, 98, 6, 2, 10, 10, 6639, 19, 14, 2, 267, 162, 711, 37, 5900, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 2, 5437, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 5664, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 7885, 5, 2, 68, 1830, 19, 6571, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 5673, 7, 15, 2, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 6676, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "        ...,\n",
              "        list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "        list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "        list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 2, 21, 4, 7298, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 5698, 3406, 718, 2, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "       dtype=object), array([0, 1, 1, ..., 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M6IEudtRE5u"
      },
      "source": [
        "xtest,ytest = data[1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyoqMwj9RI5_",
        "outputId": "76dbb218-75e0-4831-86a4-41e292e8b418"
      },
      "source": [
        "xtrain.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkVmtMn4RMSN",
        "outputId": "71bbe0e6-46db-4179-b054-423a90d1ac87"
      },
      "source": [
        "ytrain.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5SDgUeWRQdC",
        "outputId": "5fc4b1ec-f8ae-49bf-c8ed-3832892fa11d"
      },
      "source": [
        "xtest.shape,ytest.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa2RYTzzRStb",
        "outputId": "47fa2578-66bc-4a52-880e-bfa33770a715"
      },
      "source": [
        "print(xtrain[142])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 137, 13, 62, 135, 13, 358, 4, 123, 13, 873, 142, 340, 275, 39, 54, 13, 86, 219, 2, 13, 40, 44, 2, 13, 873, 8, 169, 142, 367, 4, 411, 7, 2, 2, 13, 244, 24, 252, 48, 12, 9, 170, 23, 1627, 21, 13, 28, 8, 135, 13, 81, 40, 4, 123, 5, 137, 13, 92, 2, 12, 17, 6, 9019, 123, 12, 9, 55, 1220, 5, 13, 81, 40, 4, 1175, 200, 4, 105, 17, 73, 587, 4, 696, 177, 10, 10, 13, 62, 407, 135, 15, 12, 9, 87, 8, 67, 7918, 4409, 145, 23, 4, 268, 88, 13, 66, 447, 90, 11, 543, 232, 13, 69, 82, 110, 4, 255, 37, 299, 2, 464, 11, 1063, 5, 137, 13, 104, 15, 16, 35, 864, 123, 13, 81, 24, 66, 40, 41, 109, 11, 14, 123, 88, 442, 43, 24, 61, 3647, 7, 3384, 21, 59, 7366, 12, 46, 184, 73]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2UKbUt-SPy7"
      },
      "source": [
        "# i am blue =3\n",
        "# blue is a green color = 5\n",
        "# who is red pikachu? = 4\n",
        "\n",
        "# 4 inputs only\n",
        "# ml = w1x1 + w2x2 + w3x2 + w4x4 + bias\n",
        "\n",
        "# i*w1 +am *w2 + blue*w3 + 0*w4 + bias = 0\n",
        "\n",
        "# i am blue <PAD> = 4\n",
        "# blue is a green = 4\n",
        "# who is red pikachu? = 4\n",
        "\n",
        "# <PAD> 0\n",
        "# <START> 1\n",
        "# <UNKNOWN> 2\n",
        "# <UNUSED> 3"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm1faJRpVOpg",
        "outputId": "287c007b-eb7f-4db8-8687-f354e109f99b"
      },
      "source": [
        "dictionary = nlpdata.get_word_index()\n",
        "dictionary['actor']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "281"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKAEV-FzVS_U"
      },
      "source": [
        "# elements you use more should be easier to search-> on top of dictionary, shorter numbers\n",
        "# \n",
        "revdictionary = { v:k for k,v in dictionary.items()}\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n6r6eTCGV21Y",
        "outputId": "5f43bc64-7596-476e-8229-973a335b20aa"
      },
      "source": [
        "\n",
        "revdictionary[281]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'actor'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H9WjBHYV7ao"
      },
      "source": [
        "def decode(text):\n",
        "  txt = \" \".join([ revdictionary[word] for word in text])\n",
        "  return txt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "p44u8pBfWRyK",
        "outputId": "19c62274-e9b2-4423-985d-74a71fa3c80a"
      },
      "source": [
        "decode(xtrain[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "X74rShp7WTSc",
        "outputId": "71592fc8-f744-49f0-c1f5-e60acadefbcb"
      },
      "source": [
        "print(revdictionary[1]) # START\n",
        "print(revdictionary[2]) # UNKNOWN\n",
        "print(revdictionary[3]) # UNUSED\n",
        "print(revdictionary[0]) # PAD\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "and\n",
            "a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3f3d0468b087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# UNKNOWN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# UNUSED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# PAD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u78Q8tMgYsmz"
      },
      "source": [
        "# 4 VALUES to add, and 1 of them (0) is missing!\n",
        "# move all elements in my dictionary by (4-1) = 3 elements\n",
        "corrected_dictionary = { k:v+3  for k,v in dictionary.items()}\n",
        "# MADE space to insert 0-> PAD till 3-> UNUSED into this dictionary"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reP2WEtQZZvS"
      },
      "source": [
        "corrected_dictionary['<PAD>']= 0\n",
        "corrected_dictionary['<START>']= 1\n",
        "corrected_dictionary['<UNK>']= 2\n",
        "corrected_dictionary['<UNUSED>']= 3\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwPTLWsBZkMK"
      },
      "source": [
        "wordindex = { v:k for k,v in corrected_dictionary.items()}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqgR95UWZrkv"
      },
      "source": [
        "def decode(text):\n",
        "  txt = \" \".join([ wordindex[word] for word in text])\n",
        "  return txt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bucops1YZy9I",
        "outputId": "d14b1bac-7146-4b87-f057-851afd959e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "decode(xtrain[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ThfwAgZ0vh",
        "outputId": "5ac9f482-04f8-4149-9478-29dd97a35eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "decode(xtrain[196])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> it is a superb swedish film it was the first swedish film i've seen it is simple deep what a great combination br br michael <UNK> did a great performance as a famous conductor who seeks peace in his hometown br br <UNK> <UNK> was great as his inspirational girlfriend to help him to carry on never give up br br the fight between the conductor and the <UNK> priest who loses his battle with michael when his wife confronts him and <UNK> michael's noble cause to help his hometown people finding their own peace in music br br the only thing that i didn't like was the ending it wasn't that good but it has some deep meaning\""
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWJ1kK1NZ9Ju",
        "outputId": "600123c3-ffa8-424e-bc80-d0bfc271587a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ytrain[196]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHu3rXPvaoDp"
      },
      "source": [
        "# y = mx+c => x-> it, is, a , super....\n",
        "total_length=0\n",
        "shortest, shortidx = 9999, 9999\n",
        "largest, largeidx = -1, -1\n",
        "\n",
        "for i in range(len(xtrain)):\n",
        "  length = len(xtrain[i])\n",
        "  total_length = total_length + length\n",
        "  if(length > largest):\n",
        "    largest = length\n",
        "    largeidx = i\n",
        "  if(length < shortest):\n",
        "    shortest = length\n",
        "    shortidx = i\n",
        "avg_length = total_length / len(xtrain)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upbpgklLa2Z1",
        "outputId": "e985d7db-8c4c-451c-bc6a-2153dfbea229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_length, avg_length"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5967841, 238.71364)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rggEr6uAbv9u",
        "outputId": "5b6e2280-d8f6-4c3c-90ef-f896cf884b33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "largest, largeidx"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2494, 17934)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOXoWpfPb5ma",
        "outputId": "635cc6a1-7197-4dba-a059-ed4ea7745070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shortest, shortidx"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 6719)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtjyP07-cBZr"
      },
      "source": [
        "# sentence length = 256\n",
        "HP_MAXLEN = 256"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3_Ex9k1cIqR"
      },
      "source": [
        "# output-> \n",
        "# input=> \n",
        "# input size = 10000\n",
        "# divide-> 16 = \n",
        "\n",
        "# 10,000 inputs\n",
        "# each input will be broken into 16 outputs\n",
        "# so total how many outputs for 10,000 inputs=?\n",
        "\n",
        "# 10,000X 16 = 160,000\n",
        "\n",
        "# EMBEDDING-> look up vectors behind a number\n",
        "# <42,'hello'> \n",
        "# \n",
        "\n",
        "layer1 = keras.layers.Embedding(input_dim=10000, output_dim=16)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(32)\n",
        "layer4 = keras.layers.Dense(2)\n",
        "alllayers = [layer1,layer2,layer3,layer4]\n",
        "\n",
        "model = keras.models.Sequential(alllayers)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvTw9KzChnMS",
        "outputId": "2f0d4c8d-6114-44e0-9365-0244851e270c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 160,610\n",
            "Trainable params: 160,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra_UaLglhpGU"
      },
      "source": [
        "# trainable parameters-> WEIGHTS and BIAS\n",
        "# b = 32 + 2 = 34\n",
        "# w1....w160576"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6UhsHLLihqu",
        "outputId": "f336e70d-8481-47ed-b74c-7ae610fa3869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# REGULARIZATION\n",
        "\n",
        "layer1 = keras.layers.Embedding(input_dim=10000, output_dim=32)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(64)\n",
        "layer4 = keras.layers.Dense(2)\n",
        "alllayers = [layer1,layer2,layer3,layer4]\n",
        "\n",
        "model2 = keras.models.Sequential(alllayers)\n",
        "model2.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 322,242\n",
            "Trainable params: 322,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgOy7-Ooi506"
      },
      "source": [
        "# LOSS -> how to calculate loss \n",
        "# OPTIMIZER -> how to reduce this loss\n",
        "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwt9b-uAj5mp"
      },
      "source": [
        "\n",
        "model2.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ctNlo2kwkS",
        "outputId": "f4aaed33-ffe7-4db8-c081-8355bd67be0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "paddedxtrain = keras.preprocessing.sequence.pad_sequences(xtrain, padding='post', truncating='post', maxlen=256)\n",
        "paddedxtest = keras.preprocessing.sequence.pad_sequences(xtest, padding='post', truncating='post', maxlen=256)\n",
        "paddedxtrain[0]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,\n",
              "       4468,   66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,\n",
              "        838,  112,   50,  670,    2,    9,   35,  480,  284,    5,  150,\n",
              "          4,  172,  112,  167,    2,  336,  385,   39,    4,  172, 4536,\n",
              "       1111,   17,  546,   38,   13,  447,    4,  192,   50,   16,    6,\n",
              "        147, 2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,\n",
              "         71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,\n",
              "          4,   22,   17,  515,   17,   12,   16,  626,   18,    2,    5,\n",
              "         62,  386,   12,    8,  316,    8,  106,    5,    4, 2223, 5244,\n",
              "         16,  480,   66, 3785,   33,    4,  130,   12,   16,   38,  619,\n",
              "          5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,    6,\n",
              "         22,   12,  215,   28,   77,   52,    5,   14,  407,   16,   82,\n",
              "          2,    8,    4,  107,  117, 5952,   15,  256,    4,    2,    7,\n",
              "       3766,    5,  723,   36,   71,   43,  530,  476,   26,  400,  317,\n",
              "         46,    7,    4,    2, 1029,   13,  104,   88,    4,  381,   15,\n",
              "        297,   98,   32, 2071,   56,   26,  141,    6,  194, 7486,   18,\n",
              "          4,  226,   22,   21,  134,  476,   26,  480,    5,  144,   30,\n",
              "       5535,   18,   51,   36,   28,  224,   92,   25,  104,    4,  226,\n",
              "         65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
              "        113,  103,   32,   15,   16, 5345,   19,  178,   32,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik-30MPLkBzR",
        "outputId": "26310125-cb04-4eed-cc7f-a3c2e6be750a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "starttime = time.time()\n",
        "history = model.fit(paddedxtrain,ytrain, epochs=25,verbose=1)\n",
        "endtime = time.time()\n",
        "totaltime = endtime - starttime\n",
        "print(totaltime) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5702 - accuracy: 0.5019\n",
            "Epoch 2/25\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3522 - accuracy: 0.7286\n",
            "Epoch 3/25\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.4098 - accuracy: 0.5834\n",
            "Epoch 4/25\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3396 - accuracy: 0.5273\n",
            "Epoch 5/25\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.2460 - accuracy: 0.3894\n",
            "Epoch 6/25\n",
            " 96/782 [==>...........................] - ETA: 4s - loss: 0.2130 - accuracy: 0.1370"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJF5AXABkL4p"
      },
      "source": [
        "import time\n",
        "starttime = time.time()\n",
        "history2 = model2.fit(paddedxtrain,ytrain, epochs=25,verbose=0)\n",
        "endtime = time.time()\n",
        "totaltime = endtime - starttime\n",
        "print(totaltime) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}